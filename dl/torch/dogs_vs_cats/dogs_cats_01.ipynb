{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjpOGT8OM7jo"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KedF3Y7CM_Dw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sys.version\n",
        "\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import models,transforms,datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS3d6OFvfWMx"
      },
      "source": [
        "Check if GPU is present:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm1H2MBtPBIx"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plLAlI4WMSFO"
      },
      "source": [
        "# Get dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB7kZalCMnFq"
      },
      "source": [
        "## Dowload dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT8UvxlhTDrE"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://xxxxx/dogs-vs-cats.zip -O /tmp/dogs_and_cats.zip\n",
        "\n",
        "data_zip = \"/mnt/datasets/ml/dogs-vs-cats.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPMr2huDMs3H"
      },
      "source": [
        "## Get from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyltdL7qSjFT"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIfKY2A-pbOY"
      },
      "outputs": [],
      "source": [
        "%ls /content/drive/MyDrive/\n",
        "\n",
        "drive_root = '/content/drive/MyDrive/'\n",
        "\n",
        "%ls $drive_root/dataset\n",
        "\n",
        "data_zip = os.path.join(drive_root, 'dataset/dogs-vs-cats.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbof9r_EdHfj"
      },
      "outputs": [],
      "source": [
        "%mkdir -p /tmp/dogs-vs-cats\n",
        "\n",
        "data_root = '/tmp/dogs-vs-cats'\n",
        "\n",
        "%cd $data_root\n",
        "\n",
        "%ls $data_zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdOItppjTlwu"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(data_zip, 'r')\n",
        "zip_ref.extractall(data_root)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqvtdalYctxs"
      },
      "outputs": [],
      "source": [
        "%ls /tmp/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGFYottgf56v"
      },
      "outputs": [],
      "source": [
        "# %cd /tmp/dogs-vs-cats/\n",
        "# %mkdir train\n",
        "\n",
        "train_zip = os.path.join(data_root, 'train.zip')\n",
        "zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
        "zip_ref.extractall(data_root)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%ls /tmp/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8x19mtlqVdC"
      },
      "outputs": [],
      "source": [
        "%ls /tmp/dogs-vs-cats/train/ | more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwhjsYmdlwA"
      },
      "source": [
        "# Create validation data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsjDuYScOqkj"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "files = glob(os.path.join(data_root, '*/*.jpg'))\n",
        "\n",
        "print(data_root)\n",
        "\n",
        "no_of_images = len(files)\n",
        "print(f'Total no of images {no_of_images}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMI_TyaHu7nb"
      },
      "outputs": [],
      "source": [
        "os.mkdir(os.path.join(data_root,'valid'))\n",
        "\n",
        "%ls $data_root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNojMviyvMs9"
      },
      "outputs": [],
      "source": [
        "for t in ['train','valid']:\n",
        "    for folder in ['dog/','cat/']:\n",
        "        os.mkdir(os.path.join(data_root, t, folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%ls $data_root/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%ls $data_root/valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHdSeFo6fJOR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "shuffle = np.random.permutation(no_of_images)\n",
        "\n",
        "for i in shuffle[:2000]:\n",
        "    #shutil.copyfile(files[i],'../chapter3/dogsandcats/valid/')\n",
        "    folder = files[i].split('/')[-1].split('.')[0]\n",
        "    image = files[i].split('/')[-1]\n",
        "    os.rename(files[i],os.path.join(data_root,'valid',folder,image))\n",
        "\n",
        "for i in shuffle[2000:]:\n",
        "    #shutil.copyfile(files[i],'../chapter3/dogsandcats/valid/')\n",
        "    folder = files[i].split('/')[-1].split('.')[0]\n",
        "    image = files[i].split('/')[-1]\n",
        "    os.rename(files[i],os.path.join(data_root,'train',folder,image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaR-adoyhhrX"
      },
      "outputs": [],
      "source": [
        "%ls /tmp/dogs-vs-cats/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG_DZj0hwAJt"
      },
      "outputs": [],
      "source": [
        "%ls /tmp/dogs-vs-cats/valid/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etox7QNDhsvh"
      },
      "source": [
        "# Load data into PyTorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8rEdWQChrsC"
      },
      "outputs": [],
      "source": [
        "\n",
        "simple_transform = transforms.Compose([transforms.Resize((224,224))\n",
        "                                       ,transforms.ToTensor()\n",
        "                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "train = datasets.ImageFolder('/tmp/dogs-vs-cats/train/',simple_transform)\n",
        "valid = datasets.ImageFolder('/tmp/dogs-vs-cats/valid/',simple_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9amTVGTBsCw"
      },
      "outputs": [],
      "source": [
        "print(train.classes)  #Category determined by the name of the division folder\n",
        "print(train.class_to_idx) #The index is 0,1 according to the order.\n",
        "print(train.imgs) #Returns the path of the image obtained from all folders and their categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toleKh6siR0B"
      },
      "outputs": [],
      "source": [
        "def imshow(inp):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfLne37Th5ox"
      },
      "outputs": [],
      "source": [
        "imshow(train[50][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KevgChELzZO6"
      },
      "source": [
        "# Sample 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1X1eEc_71CQ"
      },
      "source": [
        "## Create data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94UX6H2Wwfgs"
      },
      "outputs": [],
      "source": [
        "train_data_gen = torch.utils.data.DataLoader(train,batch_size=64,num_workers=2, shuffle=True)\n",
        "valid_data_gen = torch.utils.data.DataLoader(valid,batch_size=64,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXaE2T5-xD33"
      },
      "outputs": [],
      "source": [
        "dataset_sizes = {'train':len(train_data_gen.dataset),'valid':len(valid_data_gen.dataset)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMusdXDmxJs2"
      },
      "outputs": [],
      "source": [
        "dataloaders = {'train':train_data_gen,'valid':valid_data_gen}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO7JQ3f97WEv"
      },
      "source": [
        "## Create a network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A04k6y1GxUxO"
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model_ft = model_ft.cuda()\n",
        "    print('cuda true')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFGApJP0xg57"
      },
      "outputs": [],
      "source": [
        "model_ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5w6g-QAxl39"
      },
      "outputs": [],
      "source": [
        "# Loss and Optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLi5t-Q8yVkX"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for data in dataloaders[phase]:\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # wrap them in Variable\n",
        "                if torch.cuda.is_available():\n",
        "                    inputs = Variable(inputs.cuda())\n",
        "                    labels = Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                if len(list(loss.data.size())) != 0: # cggos 20211120\n",
        "                  running_loss += loss.data[0]\n",
        "                else:\n",
        "                  running_loss += loss.data.item()\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KngGBz1dyYys"
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGCDdeBszdEn"
      },
      "source": [
        "# Sample 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VBtaBy478uT"
      },
      "source": [
        "## Create data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DSm647lzoxo"
      },
      "outputs": [],
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(train,batch_size=32,num_workers=3,shuffle=True)\n",
        "valid_data_loader = torch.utils.data.DataLoader(valid,batch_size=32,num_workers=3,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rltb3UBc7mcf"
      },
      "source": [
        "## Create a network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDMkpFVezskH"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(56180, 500)\n",
        "        self.fc2 = nn.Linear(500,50)\n",
        "        self.fc3 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x,training=self.training)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x,dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ36rriAzy4d"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "\n",
        "is_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "  is_cuda = True\n",
        "  model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiKoQzsCz99p"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_uG7X4K0BSY"
      },
      "outputs": [],
      "source": [
        "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
        "    if phase == 'training':\n",
        "        model.train()\n",
        "    if phase == 'validation':\n",
        "        model.eval()\n",
        "        volatile=True\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    for batch_idx , (data,target) in enumerate(data_loader):\n",
        "        if is_cuda:\n",
        "            data,target = data.cuda(),target.cuda()\n",
        "        data , target = Variable(data,volatile),Variable(target)\n",
        "        if phase == 'training':\n",
        "            optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output,target)\n",
        "\n",
        "        loss_tmp = F.nll_loss(output,target,size_average=False)\n",
        "\n",
        "        if len(list(loss_tmp.data.size())) != 0: # cggos 20211120\n",
        "            running_loss += loss_tmp.data[0]\n",
        "        else:\n",
        "            running_loss += loss_tmp.data.item()\n",
        "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "        if phase == 'training':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    loss = running_loss/len(data_loader.dataset)\n",
        "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
        "\n",
        "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
        "    return loss,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJfOJIP0RiQ"
      },
      "outputs": [],
      "source": [
        "train_losses , train_accuracy = [],[]\n",
        "val_losses , val_accuracy = [],[]\n",
        "for epoch in range(1,20):\n",
        "    epoch_loss, epoch_accuracy = fit(epoch,model,train_data_loader,phase='training')\n",
        "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,valid_data_loader,phase='validation')\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracy.append(epoch_accuracy)\n",
        "    val_losses.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkfrJ3_7T7XP"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEMxsv4jUBTU"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'bo',label = 'train accuracy')\n",
        "plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'val accuracy')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
